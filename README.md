# Vector Similarity Search for Document Retrieval

A scalable RAG-based system with LangChain and Hugging Face, enabling automated document retrieval and intelligent question-answering for large collections of text.

## ğŸš€ Features

- **Vector Similarity Search**: HNSWlib implementation for fast approximate nearest neighbor search
- **Hugging Face Embeddings**: Sentence-transformers for semantic text embedding
- **RAG System**: Retrieval-Augmented Generation for intelligent question answering
- **FastAPI**: High-performance REST API with automatic documentation
- **Scalable Architecture**: Designed to handle large document collections

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Documents     â”‚â”€â”€â”€â–¶â”‚   Embedder      â”‚â”€â”€â”€â–¶â”‚   Vector Index  â”‚
â”‚   (Text Files)  â”‚    â”‚ (Hugging Face)  â”‚    â”‚   (HNSWlib)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   Query         â”‚â”€â”€â”€â–¶â”‚   FastAPI       â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   (User Input)  â”‚    â”‚   Endpoints      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Requirements

- Python 3.9+
- FastAPI
- sentence-transformers
- hnswlib
- langchain
- torch
- transformers

## ğŸ› ï¸ Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd vector-similarity-search-for-Document-Retrieval
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Prepare sample data**
   ```bash
   # Sample documents are already included in example_data/documents.txt
   ```

## ğŸš€ Quick Start

1. **Run the system test**
   ```bash
   python3 test_system.py
   ```

2. **Start the API server**
   ```bash
   python3 main.py
   ```

3. **Access the API documentation**
   - Open your browser to `http://localhost:8000/docs`
   - Interactive API documentation with Swagger UI

## ğŸ“š API Endpoints

### Core Endpoints

- **GET `/`** - Welcome message and API information
- **GET `/health`** - Health check endpoint
- **GET `/docs`** - Interactive API documentation

### Vector Search Endpoints

- **POST `/api/search`** - Vector similarity search
  ```json
  {
    "query": "machine learning algorithms",
    "top_k": 5,
    "threshold": 0.0
  }
  ```

- **POST `/api/qa`** - Question answering with RAG
  ```json
  {
    "query": "What is machine learning?",
    "top_k": 3
  }
  ```

- **GET `/api/stats`** - Index statistics
- **POST `/api/reindex`** - Rebuild vector index

## ğŸ”§ Usage Examples

### 1. Vector Similarity Search

```bash
curl -X POST "http://localhost:8000/api/search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "deep learning neural networks",
    "top_k": 3,
    "threshold": 0.3
  }'
```

**Response:**
```json
{
  "query": "deep learning neural networks",
  "results": [
    {
      "document": "Deep learning neural networks for computer vision...",
      "document_id": "doc_1",
      "score": 0.8234,
      "distance": 0.1766
    }
  ],
  "total_found": 3,
  "returned": 3
}
```

### 2. Question Answering (RAG)

```bash
curl -X POST "http://localhost:8000/api/qa" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What is machine learning?",
    "top_k": 2
  }'
```

**Response:**
```json
{
  "question": "What is machine learning?",
  "answer": "Based on the available information: Machine learning is a subset of artificial intelligence...",
  "sources": [...],
  "context_used": "Introduction to machine learning algorithms..."
}
```

### 3. Index Statistics

```bash
curl -X GET "http://localhost:8000/api/stats"
```

**Response:**
```json
{
  "index_stats": {
    "total_documents": 10,
    "embedding_dimension": 384,
    "max_elements": 20000,
    "current_size": 10
  },
  "embedder_info": {
    "model": "all-MiniLM-L6-v2",
    "dimension": 384
  },
  "status": "ready"
}
```

## ğŸ§ª Testing

### Run System Tests
```bash
python3 test_system.py
```

### Run API Tests
```bash
python3 -m pytest tests/tests_endpoints.py -v
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ endpoints.py          # FastAPI endpoints
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ embedder.py          # Hugging Face embeddings
â”‚   â””â”€â”€ index/
â”‚       â””â”€â”€ index_manager.py     # HNSWlib vector index
â”œâ”€â”€ example_data/
â”‚   â””â”€â”€ documents.txt            # Sample documents
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ tests_endpoints.py       # API tests
â”œâ”€â”€ data/                        # Vector index storage
â”œâ”€â”€ main.py                      # FastAPI application
â”œâ”€â”€ test_system.py              # System integration tests
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # This file
```

## ğŸ”§ Configuration

### Embedding Model
The system uses `all-MiniLM-L6-v2` by default. To change the model:

```python
# In src/embeddings/embedder.py
embedder = Embedder(model_name='your-preferred-model')
```

### Index Parameters
Adjust HNSWlib parameters in `src/index/index_manager.py`:

```python
index_manager = IndexManager(
    dim=384,           # Embedding dimension
    max_elements=20000, # Maximum documents
    index_path="data/vector_index"  # Storage path
)
```

## ğŸš€ Deployment

### Local Development
```bash
python3 main.py
```

### Production (with uvicorn)
```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Docker
```bash
docker build -t vector-search-api .
docker run -p 8000:8000 vector-search-api
```

## ğŸ“Š Performance

- **Embedding Generation**: ~100ms per document (CPU)
- **Vector Search**: ~1-5ms per query (10K documents)
- **Memory Usage**: ~50MB for 10K documents (384-dim embeddings)
- **Index Size**: ~15MB for 10K documents

## ğŸ” Technical Details

### Embeddings
- **Model**: `all-MiniLM-L6-v2` (384 dimensions)
- **Provider**: Hugging Face sentence-transformers
- **Backend**: PyTorch

### Vector Search
- **Algorithm**: HNSW (Hierarchical Navigable Small World)
- **Library**: hnswlib
- **Distance Metric**: Cosine similarity
- **Search Parameters**: ef=50, M=16

### RAG Implementation
- **Retrieval**: Vector similarity search
- **Generation**: Simple keyword-based (extensible to LLMs)
- **Context**: Top-k relevant documents

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- [Hugging Face](https://huggingface.co/) for sentence-transformers
- [hnswlib](https://github.com/nmslib/hnswlib) for vector search
- [FastAPI](https://fastapi.tiangolo.com/) for the web framework
- [LangChain](https://langchain.com/) for RAG framework

## ğŸ“ Support

For questions and support, please open an issue in the repository.

---

**Built with â¤ï¸ for scalable document retrieval and intelligent question answering**